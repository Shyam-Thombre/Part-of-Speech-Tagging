{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_Tagger_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFBZo0JkujXB",
        "outputId": "48be60c6-a4db-4322-d4c6-7ea1a98ff90e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWWOcCG48YXR"
      },
      "source": [
        "!mkdir pos_tagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITknXBMj9P1W",
        "outputId": "ec86281c-551e-472c-949b-001589409e0f"
      },
      "source": [
        "cd pos_tagger"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pos_tagger\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfCGg7Ke8Zxx",
        "outputId": "ff734587-6f2f-4555-bf71-e55836dc6c95"
      },
      "source": [
        "!wget http://www.cnts.ua.ac.be/conll2000/chunking/train.txt.gz -O - | gunzip | cut -f1,2 -d\" \" > pos.train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-23 10:24:55--  http://www.cnts.ua.ac.be/conll2000/chunking/train.txt.gz\n",
            "Resolving www.cnts.ua.ac.be (www.cnts.ua.ac.be)... 146.175.13.81\n",
            "Connecting to www.cnts.ua.ac.be (www.cnts.ua.ac.be)|146.175.13.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.clips.uantwerpen.be/conll2000/chunking/train.txt.gz [following]\n",
            "--2021-04-23 10:24:55--  https://www.clips.uantwerpen.be/conll2000/chunking/train.txt.gz\n",
            "Resolving www.clips.uantwerpen.be (www.clips.uantwerpen.be)... 146.175.13.81\n",
            "Connecting to www.clips.uantwerpen.be (www.clips.uantwerpen.be)|146.175.13.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 611540 (597K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 597.21K  1.35MB/s    in 0.4s    \n",
            "\n",
            "2021-04-23 10:24:56 (1.35 MB/s) - written to stdout [611540/611540]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c0q0RxD9V0K",
        "outputId": "bb16f1d3-49b6-4df3-b53d-b3ee66e19ee2"
      },
      "source": [
        "!wget http://www.cnts.ua.ac.be/conll2000/chunking/test.txt.gz -O - | gunzip | cut -f1,2 -d \" \" > pos.test.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-23 10:24:57--  http://www.cnts.ua.ac.be/conll2000/chunking/test.txt.gz\n",
            "Resolving www.cnts.ua.ac.be (www.cnts.ua.ac.be)... 146.175.13.81\n",
            "Connecting to www.cnts.ua.ac.be (www.cnts.ua.ac.be)|146.175.13.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.clips.uantwerpen.be/conll2000/chunking/test.txt.gz [following]\n",
            "--2021-04-23 10:24:57--  https://www.clips.uantwerpen.be/conll2000/chunking/test.txt.gz\n",
            "Resolving www.clips.uantwerpen.be (www.clips.uantwerpen.be)... 146.175.13.81\n",
            "Connecting to www.clips.uantwerpen.be (www.clips.uantwerpen.be)|146.175.13.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139551 (136K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 136.28K   531KB/s    in 0.3s    \n",
            "\n",
            "2021-04-23 10:24:57 (531 KB/s) - written to stdout [139551/139551]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD8jmwzci2Qe",
        "outputId": "90e5f2bd-177a-4ff9-df5d-fc854b8f5a29"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices()[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14674281152\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 3742605192665031431\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGYk_FU7l8eH",
        "outputId": "12a2a63c-9e68-4710-f59c-b62877ca9494"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDWcljAbOA_C"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "import math\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2XoleOfKsLT",
        "outputId": "3e4c2c78-0d79-4415-9399-3ab7626df815"
      },
      "source": [
        "# transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
        "enc_layer = nn.TransformerEncoderLayer(512, 8, 2048, 0.1)\n",
        "encoder = nn.TransformerEncoder(enc_layer, 6)\n",
        "src = torch.rand((10, 32, 512))\n",
        "# tgt = torch.rand((20, 32, 512))\n",
        "out = encoder(src)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 32, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7Gh2mv3OI2y",
        "outputId": "25b0715e-5b67-40db-b1e3-c9e9d1dd78a4"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeBYYpX4OKnu"
      },
      "source": [
        "random_seed = 20\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.set_printoptions(threshold=2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uc5RanSeVAs"
      },
      "source": [
        "remove_tags = ['.',',','(',')',':','``',\"''\",'#','$']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8mkmUcN_RYJ"
      },
      "source": [
        "train_file = \"pos.train.txt\"\n",
        "test_file = \"pos.test.txt\"\n",
        "\n",
        "def create_dataset(filename):\n",
        "    data = []\n",
        "    label = []\n",
        "    with open(filename, 'r') as f:\n",
        "        x = []\n",
        "        y = []\n",
        "        for line in f:\n",
        "            s = line.split()\n",
        "            if s == []:\n",
        "                data.append(\" \".join(x))\n",
        "                label.append(\" \".join(y))\n",
        "                x = []\n",
        "                y = []\n",
        "                continue\n",
        "            x.append(s[0])\n",
        "            if s[1] in remove_tags:\n",
        "                y.append(\"PUN\")\n",
        "            else:\n",
        "                y.append(s[1])\n",
        "    return data, label\n",
        "\n",
        "X_train, y_train_tags = create_dataset(train_file)\n",
        "X_test, y_test_tags = create_dataset(test_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhA61ifLnZrh"
      },
      "source": [
        "for i in range(len(X_train)):\n",
        "    assert(len(X_train[i].split()) == len(y_train_tags[i].split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmGJtbCVATmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9a5512-123a-42a0-d425-7519ea18339b"
      },
      "source": [
        "indx = 3\n",
        "\n",
        "print(X_train[indx])\n",
        "print(len(X_train[indx].split()))\n",
        "\n",
        "print(y_train_tags[indx])\n",
        "print(len(y_train_tags[indx].split()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This has increased the risk of the government being forced to increase base rates to 16 % from their current 15 % level to defend the pound , economists and foreign exchange market analysts say .\n",
            "36\n",
            "DT VBZ VBN DT NN IN DT NN VBG VBN TO VB NN NNS TO CD NN IN PRP$ JJ CD NN NN TO VB DT NN PUN NNS CC JJ NN NN NNS VBP PUN\n",
            "36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Poiz999qfjQp",
        "outputId": "6b22e7dc-e68b-461f-e76a-6abd7835f9db"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU4NaVlYNDVl",
        "outputId": "90b04160-e903-41b0-e713-707132e58354"
      },
      "source": [
        "POS_tags = {}\n",
        "for line in y_train_tags:\n",
        "    s = line.split()\n",
        "    for elem in s:\n",
        "        if elem not in POS_tags:\n",
        "            POS_tags[elem] = 1\n",
        "        else:\n",
        "            POS_tags[elem] += 1\n",
        "print(len(POS_tags))\n",
        "print(POS_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "{'NN': 30147, 'IN': 22764, 'DT': 18335, 'VBZ': 4648, 'RB': 6607, 'VBN': 4763, 'TO': 5081, 'VB': 6017, 'JJ': 13085, 'NNS': 13619, 'NNP': 19884, 'PUN': 26009, 'CC': 5372, 'POS': 1769, 'VBP': 2868, 'VBG': 3272, 'PRP$': 1881, 'CD': 8315, 'VBD': 6745, 'EX': 206, 'MD': 2167, 'NNPS': 420, 'PRP': 3820, 'JJS': 374, 'WP': 529, 'RBR': 321, 'JJR': 853, 'WDT': 955, 'WRB': 478, 'RBS': 191, 'PDT': 55, 'RP': 83, 'FW': 38, 'WP$': 35, 'SYM': 6, 'UH': 15}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBKZ3RJ1O7Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e881fb3-15a7-4049-8742-6f0fee2511ae"
      },
      "source": [
        "tag_to_idx = {\"<PAD>\": 0}\n",
        "idx_to_tag = {0: \"<PAD>\"}\n",
        "for tag in POS_tags.keys():\n",
        "    indx = len(tag_to_idx)\n",
        "    tag_to_idx[tag] = indx\n",
        "    idx_to_tag[indx] = tag\n",
        "print(tag_to_idx)\n",
        "print(idx_to_tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<PAD>': 0, 'NN': 1, 'IN': 2, 'DT': 3, 'VBZ': 4, 'RB': 5, 'VBN': 6, 'TO': 7, 'VB': 8, 'JJ': 9, 'NNS': 10, 'NNP': 11, 'PUN': 12, 'CC': 13, 'POS': 14, 'VBP': 15, 'VBG': 16, 'PRP$': 17, 'CD': 18, 'VBD': 19, 'EX': 20, 'MD': 21, 'NNPS': 22, 'PRP': 23, 'JJS': 24, 'WP': 25, 'RBR': 26, 'JJR': 27, 'WDT': 28, 'WRB': 29, 'RBS': 30, 'PDT': 31, 'RP': 32, 'FW': 33, 'WP$': 34, 'SYM': 35, 'UH': 36}\n",
            "{0: '<PAD>', 1: 'NN', 2: 'IN', 3: 'DT', 4: 'VBZ', 5: 'RB', 6: 'VBN', 7: 'TO', 8: 'VB', 9: 'JJ', 10: 'NNS', 11: 'NNP', 12: 'PUN', 13: 'CC', 14: 'POS', 15: 'VBP', 16: 'VBG', 17: 'PRP$', 18: 'CD', 19: 'VBD', 20: 'EX', 21: 'MD', 22: 'NNPS', 23: 'PRP', 24: 'JJS', 25: 'WP', 26: 'RBR', 27: 'JJR', 28: 'WDT', 29: 'WRB', 30: 'RBS', 31: 'PDT', 32: 'RP', 33: 'FW', 34: 'WP$', 35: 'SYM', 36: 'UH'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fAyr7LL30Xh"
      },
      "source": [
        "y_train = []\n",
        "for line in y_train_tags:\n",
        "    labels = line.split()\n",
        "    labels = [tag_to_idx[x] for x in labels]\n",
        "    y_train.append(labels)\n",
        "\n",
        "y_test = []\n",
        "for line in y_test_tags:\n",
        "    labels = line.split()\n",
        "    labels = [tag_to_idx[x] for x in labels]\n",
        "    y_test.append(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "lnnV8qymfUNC",
        "outputId": "4fd03ae8-7c63-4a7e-ff45-e9fee3836e6b"
      },
      "source": [
        "length = []\n",
        "for row in X_train:\n",
        "  length.append(len(row.split()))\n",
        "for row in X_test:\n",
        "  length.append(len(row.split()))\n",
        "\n",
        "mean = sum(length)/len(length)\n",
        "print(f'''Mean = {mean}\n",
        "Max = {max(length)}\n",
        "Min = {min(length)}''')\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.hist(length)\n",
        "plt.xlabel(\"Length\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean = 23.66678845451224\n",
            "Max = 78\n",
            "Min = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9TUAMLMiMol"
      },
      "source": [
        "embed_length = 100\n",
        "output_dim = len(tag_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "athGKhEWidaB"
      },
      "source": [
        "def convert_to_lower(text):\n",
        "    # return the reviews after convering then to lowercase\n",
        "    for i in range(len(text)):\n",
        "        text[i] = text[i].lower()\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGf1zbYsllb5"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    # return the reviews after removing punctuations\n",
        "    for i in range(len(text)):\n",
        "        text[i] = re.sub(r'[^\\w\\s]', '', text[i])\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj3w289RllQK"
      },
      "source": [
        "def perform_tokenization(text):\n",
        "    # return the reviews after performing tokenization\n",
        "    tokanized_text = []\n",
        "    for i in range(len(text)):\n",
        "        s = text[i].split()\n",
        "        tokanized_text.append(s)\n",
        "    return tokanized_text "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VuPszMyllNY"
      },
      "source": [
        "def encode_data(text, vocab2index=None):\n",
        "    if vocab2index is None:\n",
        "        vocab2index = {\"<PAD>\":0, \" \":1, \"UNK\":2}\n",
        "        words = [\"<PAD>\", \" \", \"UNK\"]\n",
        "        for i in range(len(text)):\n",
        "            s = text[i]\n",
        "            for word in s:\n",
        "                if word not in words:\n",
        "                    vocab2index[word] = len(words)\n",
        "                    words.append(word)\n",
        "\n",
        "    for i in range(len(text)):\n",
        "        s = text[i]\n",
        "        enc_s = []\n",
        "        for word in s:\n",
        "            if word in vocab2index.keys():\n",
        "                enc_s.append(vocab2index[word])\n",
        "            else:\n",
        "                enc_s.append(2)\n",
        "        text[i] = enc_s\n",
        "    \n",
        "    return text, vocab2index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68pzwPiVoqtq"
      },
      "source": [
        "def perform_padding(text, labels, maxLen=None):\n",
        "    # return the reviews after padding the reviews to maximum \n",
        "    lengths = []\n",
        "    if maxLen is None:\n",
        "        maxLen = max([len(s) for s in text])\n",
        "\n",
        "    for i in range(len(text)):\n",
        "        l = len(text[i])\n",
        "        lengths.append(l)\n",
        "        zeros = []\n",
        "        if l < maxLen:\n",
        "            zeros = [0]*(maxLen-l)\n",
        "        text[i] = text[i][:maxLen] + zeros\n",
        "        labels[i] = labels[i][:maxLen] + zeros\n",
        "    return torch.tensor(text), torch.tensor(labels), torch.tensor(lengths), maxLen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxu9-zZ1ot4J"
      },
      "source": [
        "def preprocess_data(data, labels, vocab2index=None, maxLen=None):\n",
        "    data = convert_to_lower(data)\n",
        "    # data = remove_punctuation(data)\n",
        "    data = perform_tokenization(data)\n",
        "    data, vocab2index = encode_data(data, vocab2index)\n",
        "    data, labels, lengths, maxLen = perform_padding(data, labels, maxLen)\n",
        "    return data, labels, lengths, vocab2index, maxLen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jU54428Iz5tv"
      },
      "source": [
        "#@title Plot Grad Flow\n",
        "def plot_grad_flow(named_parameters):\n",
        "    ave_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eVv-N4aoyij",
        "cellView": "form"
      },
      "source": [
        "#@title Evaluate Function\n",
        "\n",
        "def evaluate(X, y, model):\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "  labels = []\n",
        "  loss_list = []\n",
        "  batch_size = 32\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(0, len(X), batch_size):\n",
        "      x = Variable(X[i:i+batch_size])\n",
        "      label = Variable(y[i:i+batch_size])\n",
        "\n",
        "      out, _ = model(x)\n",
        "      out = out.view(-1, out.shape[-1])\n",
        "      label = label.view(-1)\n",
        "\n",
        "      loss = F.cross_entropy(out, label)\n",
        "      loss_list.append(loss.item())\n",
        "      labels += label.cpu().detach().tolist()\n",
        "\n",
        "      out = torch.max(out, 1)[1]\n",
        "      predictions += out.cpu().detach().tolist()\n",
        "\n",
        "  acc = accuracy_score(labels, predictions)\n",
        "  return acc*100, np.mean(loss_list)/len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp40LuZ0pH0g",
        "cellView": "form",
        "outputId": "15e5333a-2185-4d2a-e7e8-7d7348638d0b"
      },
      "source": [
        "#@title Get Glove embeddings\n",
        "embeddings_index = {}\n",
        "f = open(f'../drive/My Drive/CS772/Assignment1/GloVe/glove.6B.{embed_length}d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print(f'Collecting {embed_length}d Glove embeddings')\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting 100d Glove embeddings\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV0K9t8npH7r",
        "cellView": "form"
      },
      "source": [
        "#@title Create Embedding Matrix\n",
        "def create_embedding_matrix(vocab2index, embeddings_index):\n",
        "    VOCAB_SIZE = len(vocab2index.keys())\n",
        "    cnt = 0\n",
        "    embedding_matrix = np.zeros((VOCAB_SIZE, embed_length))\n",
        "    for word, i in vocab2index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "        else:\n",
        "            torch.Tensor.normal_(torch.Tensor(embedding_matrix[i])).numpy()\n",
        "            cnt += 1\n",
        "    embedding_matrix = torch.Tensor(embedding_matrix)\n",
        "    print(f\"Number of words not found: {cnt}\")\n",
        "    return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhy2GHKLpH5m",
        "cellView": "form"
      },
      "source": [
        "#@title Create Embedding Layer\n",
        "def create_emb_layer(weights_matrix, trainable=True):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
        "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "    if not trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "    return emb_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lfMsZP6DNY"
      },
      "source": [
        "maxLen = None\n",
        "\n",
        "X_train, y_train, l_train, vocab2index, maxLen = preprocess_data(X_train, y_train, maxLen=maxLen)\n",
        "X_test, y_test, l_test, _, _ = preprocess_data(X_test, y_test, vocab2index, maxLen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb4gepC3prLv"
      },
      "source": [
        "datalen = len(X_train)\n",
        "trainset_frac = 0.8\n",
        "trainidx = int(datalen*trainset_frac)\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "\n",
        "train_data, train_label, train_lengths = X_train[:trainidx], y_train[:trainidx], l_train[:trainidx]\n",
        "val_data, val_label, val_lengths = X_train[trainidx:], y_train[trainidx:], l_test[trainidx:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6848kCf2A6c"
      },
      "source": [
        "X_train, y_train = train_data.to(device), train_label.to(device)\n",
        "X_val, y_val = val_data.to(device), val_label.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ChfuR8I-XQx"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=78):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, nheads, nlayers, dropout,\n",
        "                 embedding_matrix, pretrained_embed, trainable_embeddings):\n",
        "        super(TransformerNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        if pretrained_embed:\n",
        "            self.embedding = create_emb_layer(embedding_matrix, trainable_embeddings)\n",
        "        else:\n",
        "            num_embeddings, embedding_dim = embedding_matrix.shape\n",
        "            self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
        "        \n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(input_dim, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(input_dim, nheads, hidden_dim, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "        nn.init.normal_(self.fc.weight,0.0,1.0)\n",
        "    \n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, has_mask=True):\n",
        "        src = src.permute(1, 0)\n",
        "        if has_mask:\n",
        "            device = src.device\n",
        "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "                self.src_mask = mask\n",
        "        else:\n",
        "            self.src_mask = None\n",
        "\n",
        "        src = self.embedding(src) * math.sqrt(self.input_dim)\n",
        "        src = self.pos_encoder(src)\n",
        "        out = self.transformer_encoder(src, self.src_mask)\n",
        "        out = self.dropout(out)\n",
        "        enc_out = out.permute(1, 0, 2)\n",
        "        out = self.fc(enc_out)\n",
        "        return out, enc_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-3BML8v1cg1"
      },
      "source": [
        "class POS_Tagger():\n",
        "    def __init__(self, X_train, y_train, l_train, X_val, y_val, l_val):\n",
        "        super(POS_Tagger, self).__init__()\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.l_train = l_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.l_val = l_val\n",
        "\n",
        "    def train(self, input_dim, hidden_dim, output_dim, nheads, nlayers, dropout, \n",
        "              vocab2index, embeddings_index, pretrained_embed, trainable_embedding):    \n",
        "        train_loss = []\n",
        "        train_accu = []\n",
        "        val_loss = []\n",
        "        val_accu = []\n",
        "        epoch_times = []\n",
        "        train_los = 0.\n",
        "        train_acc = 0.\n",
        "        val_los = 0.\n",
        "        val_acc = 0.\n",
        "\n",
        "        X_train = self.X_train\n",
        "        y_train = self.y_train\n",
        "        l_train = self.l_train\n",
        "        X_val = self.X_val\n",
        "        y_val = self.y_val\n",
        "        l_val = self.l_val\n",
        "\n",
        "        print(\"######## Hyper Parameters #########\")\n",
        "        print(\"Learning Rate: {}\".format(learn_rate))\n",
        "        print(\"Batch Size: {}\".format(batch_size))\n",
        "        print(\"Num Epochs: {}\".format(epochs))\n",
        "        print(\"###################################\")\n",
        "\n",
        "        max_length = 30147\n",
        "\n",
        "        embedding_matrix = create_embedding_matrix(vocab2index, embeddings_index)\n",
        "        model = TransformerNet(input_dim, hidden_dim, output_dim, nheads, nlayers, dropout, \n",
        "                               embedding_matrix, pretrained_embed, trainable_embedding).to(device)\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "        print(\"Starting training the model\")\n",
        "\n",
        "        for epoch in range(1, epochs+1):\n",
        "            start_time = time.perf_counter()\n",
        "            avg_loss = 0.\n",
        "            counter = 0  \n",
        "            outs = []\n",
        "            labels = []\n",
        "\n",
        "            X_train, y_train = shuffle(X_train, y_train)\n",
        "            \n",
        "            train_labels = y_train.cpu().long().numpy()\n",
        "\n",
        "            if sampling==\"oversampling\":\n",
        "                indx= np.array([])\n",
        "                for i in range(5):\n",
        "                    idx = np.where(train_labels==i)[0]\n",
        "                    mult = max_length//len(idx)\n",
        "                    indx = np.append(indx, idx.repeat(mult))\n",
        "                X_temp, y_temp = shuffle(X_train[indx], y_train[indx])              \n",
        "            else:\n",
        "                X_temp, y_temp = shuffle(X_train, y_train)\n",
        "            \n",
        "            X_temp, y_temp = shuffle(X_temp, y_temp)\n",
        "            dataset_len = len(y_temp)\n",
        "\n",
        "            for i in range(0, dataset_len, batch_size):\n",
        "                if i + batch_size >= dataset_len:\n",
        "                    plot_grad_flow(model.named_parameters())\n",
        "                    break\n",
        "\n",
        "                model.train()\n",
        "                model.zero_grad()\n",
        "\n",
        "                counter += batch_size\n",
        "\n",
        "                x = Variable(X_temp[i:i+batch_size])\n",
        "                label = Variable(y_temp[i:i+batch_size])\n",
        "\n",
        "                out, _ = model(x)\n",
        "                \n",
        "                out = out.view(-1, out.shape[-1])\n",
        "                label = label.view(-1)\n",
        "                \n",
        "                loss = criterion(out, label)\n",
        "                avg_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                out = torch.max(out, 1)[1]\n",
        "                outs += out.cpu().detach().tolist()\n",
        "                labels += label.cpu().detach().tolist()\n",
        "\n",
        "            train_acc = accuracy_score(labels, outs)*100\n",
        "            train_los = avg_loss/counter\n",
        "            val_acc, val_los = evaluate(X_val, y_val, model)\n",
        "            train_loss.append(train_los)\n",
        "            train_accu.append(train_acc)\n",
        "            val_loss.append(val_los)\n",
        "            val_accu.append(val_acc)\n",
        "\n",
        "            current_time = time.perf_counter()\n",
        "            print(\"Epoch {}/{} Done | Train Loss: {:.3f} | Train Accu: {:.4f} | Val Loss: {:.3f} | Val Accu: {:.4f} | Time Elapsed: {:.2f}\\n\".format(epoch, epochs, avg_loss/counter, train_acc, val_los, val_acc, current_time-start_time))\n",
        "            epoch_times.append(current_time-start_time)\n",
        "        print(\"Total Training Time: {} seconds\".format(sum(epoch_times)))\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.subplot(121)\n",
        "        plt.title(\"Training Loss\")\n",
        "        plt.plot(train_loss)\n",
        "\n",
        "        plt.subplot(122)\n",
        "        plt.title(\"Validation Loss\")\n",
        "        plt.plot(val_loss)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd94KnUK58T6"
      },
      "source": [
        "learn_rate, batch_size, epochs = 0.001, 128, 15\n",
        "\n",
        "hidden_dim = 256\n",
        "nheads = 10\n",
        "nlayers = 6\n",
        "dropout = 0.2\n",
        "pretrained_embed = True\n",
        "trainable_embedding = True\n",
        "\n",
        "sampling = \"oversampling\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Hdt3iK6RE3bm",
        "outputId": "76bf7a86-b991-4cfe-8526-d78777af35c9"
      },
      "source": [
        "tagger = POS_Tagger(X_train, y_train, train_lengths, X_val, y_val, val_lengths)\n",
        "model = tagger.train(embed_length, hidden_dim, output_dim, nheads, nlayers, dropout, \n",
        "                     vocab2index, embeddings_index, pretrained_embed, trainable_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9946f62eaabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOS_Tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model = tagger.train(embed_length, hidden_dim, output_dim, nheads, nlayers, dropout, \n\u001b[1;32m      3\u001b[0m                      vocab2index, embeddings_index, pretrained_embed, trainable_embedding)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'POS_Tagger' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouvduijDCEAj",
        "outputId": "db7e501a-5bad-42ef-c310-c57917162c4f"
      },
      "source": [
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "test_acc, test_los = evaluate(X_test, y_test, model)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.44186165060916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrlJ5F3tCEC0"
      },
      "source": [
        "def test(X, y, model):\n",
        "    model.eval()\n",
        "    enc_outs = []\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    batch_size = 64\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            x = Variable(X[i:i+batch_size])\n",
        "            label = Variable(y[i:i+batch_size])\n",
        "\n",
        "            out, enc_out = model(x)\n",
        "            out = out.view(-1, out.shape[-1])\n",
        "            label = label.view(-1)\n",
        "\n",
        "            enc_out = enc_out.reshape(-1, enc_out.shape[-1])\n",
        "            enc_outs += enc_out.cpu().detach().tolist()\n",
        "\n",
        "            preds = torch.max(out, 1)[1]\n",
        "            predictions += preds.cpu().detach().tolist()\n",
        "            labels += label.cpu().detach().tolist()\n",
        "\n",
        "    return predictions, labels, enc_outs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6AXqzXQ64rR",
        "outputId": "a0320382-3bd7-4773-d8fa-276d01be5c9a"
      },
      "source": [
        "preds, label, _ = test(X_test, y_test, model)\n",
        "print(confusion_matrix(label, preds))\n",
        "f = f1_score(label, preds, average=None)\n",
        "print(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[109558      0      0 ...      0      0      0]\n",
            " [   545   5704      3 ...      0      0      0]\n",
            " [     1      0   5046 ...      0      0      0]\n",
            " ...\n",
            " [     1      0      0 ...      0      0      0]\n",
            " [     0      0      0 ...      0      0      0]\n",
            " [     1      0      0 ...      0      0      0]]\n",
            "[0.98693343 0.87210458 0.97885548 0.99178287 0.93226177 0.9076087\n",
            " 0.76959174 1.         0.83261126 0.83534691 0.90196738 0.75129662\n",
            " 0.99956811 0.99587118 0.98177677 0.79708637 0.8706578  1.\n",
            " 0.91333708 0.88525583 0.97959184 0.98739496 0.         0.99938537\n",
            " 0.86764706 1.         0.60176991 0.86524823 0.72566372 0.99459459\n",
            " 0.93203883 0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d33e8mLSq_U_",
        "outputId": "82b3cef5-1de3-462b-abb2-6e64d486c7de"
      },
      "source": [
        "new_labels = []\n",
        "new_preds = []\n",
        "for i in range(len(label)):\n",
        "    if label[i] != 0 and label[i] != tag_to_idx[\"PUN\"]:\n",
        "        new_labels.append(label[i])\n",
        "        new_preds.append(preds[i])\n",
        "\n",
        "acc = accuracy_score(new_labels, new_preds)*100\n",
        "cm = confusion_matrix(new_labels, new_preds)\n",
        "f = f1_score(new_labels, new_preds, average=None)\n",
        "\n",
        "print(acc)\n",
        "print(cm)\n",
        "print(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86.58683210695908\n",
            "[[   0    0    0 ...    0    0    0]\n",
            " [ 545 5704    3 ...    0    0    0]\n",
            " [   1    0 5046 ...    0    0    0]\n",
            " ...\n",
            " [   1    0    0 ...    0    0    0]\n",
            " [   0    0    0 ...    0    0    0]\n",
            " [   1    0    0 ...    0    0    0]]\n",
            "[0.         0.87210458 0.97885548 0.99178287 0.93226177 0.9076087\n",
            " 0.76959174 1.         0.83261126 0.83534691 0.90196738 0.75129662\n",
            " 0.99587118 0.98739977 0.79708637 0.8706578  1.         0.91359415\n",
            " 0.88525583 0.97959184 0.98739496 0.         0.99938537 0.86764706\n",
            " 1.         0.60176991 0.86524823 0.72566372 0.99459459 0.93203883\n",
            " 0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuHLcA70Rrdo",
        "outputId": "dae0e34a-bcf0-4200-c278-502df2386581"
      },
      "source": [
        "# len(np.unique(y_test.cpu().detach().numpy()))\n",
        "print(np.unique(new_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24\n",
            " 25 26 27 28 29 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crt7tnj8Tw04",
        "outputId": "0bf8d758-ad92-4070-f80c-8711e44cb865"
      },
      "source": [
        "POS_tags_test = {}\n",
        "for line in y_test_tags:\n",
        "    s = line.split()\n",
        "    for elem in s:\n",
        "        if elem not in POS_tags_test:\n",
        "            POS_tags_test[elem] = 1\n",
        "        else:\n",
        "            POS_tags_test[elem] += 1\n",
        "print(len(POS_tags_test))\n",
        "print(POS_tags_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35\n",
            "{'NNP': 4806, 'POS': 434, 'NN': 6642, 'VBD': 1679, 'PRP': 814, 'DT': 4020, 'JJ': 2964, 'VBG': 728, 'PRP$': 421, 'IN': 5071, 'TO': 1178, 'VB': 1269, 'NNS': 3034, 'CD': 1918, 'PUN': 5791, 'VBZ': 913, 'VBP': 539, 'VBN': 1104, 'CC': 1214, 'RB': 1354, 'WDT': 202, 'WP': 110, 'RBR': 71, 'JJR': 202, 'NNPS': 130, 'MD': 470, 'WRB': 93, 'JJS': 77, 'EX': 48, 'WP$': 4, 'RP': 12, 'UH': 2, 'RBS': 49, 'FW': 4, 'PDT': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BjFw5L_7SO5"
      },
      "source": [
        "def tag_sentence(data, vocab2index, model):\n",
        "    model.eval()\n",
        "    data = convert_to_lower(data)\n",
        "    # data = remove_punctuation(data)\n",
        "    data = perform_tokenization(data)\n",
        "    data, vocab2index = encode_data(data, vocab2index)\n",
        "    data = Variable(torch.tensor(data)).to(device)\n",
        "    out, enc_out = model(data)\n",
        "    out = out.view(-1, out.shape[-1])\n",
        "    preds = torch.max(out, 1)[1]\n",
        "    tags = [idx_to_tag[int(x)] for x in preds]\n",
        "    return tags, enc_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVThXJCEPr1a",
        "outputId": "3f0ea5c9-f8a2-4dc3-ddfb-a1bbd3310b85"
      },
      "source": [
        "s = [\"Delhi is the capital of India .\"]\n",
        "tags, enc_out = tag_sentence(s, vocab2index, model)\n",
        "for i in range(len(tags)):\n",
        "    print(f\"{s[0].split()[i]}\\t:\\t{tags[i]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "delhi\t:\t<PAD>\n",
            "is\t:\tVBZ\n",
            "the\t:\tDT\n",
            "capital\t:\tNN\n",
            "of\t:\tIN\n",
            "india\t:\tNNP\n",
            ".\t:\tPUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwy60Qc-SLt8"
      },
      "source": [
        "_, train_labels, train_enc_outs = test(X_train, y_train, model)\n",
        "_, val_labels, val_enc_outs = test(X_val, y_val, model)\n",
        "\n",
        "train_labels = np.append(train_labels, val_labels, axis=0)\n",
        "train_enc_outs = np.append(train_enc_outs, val_enc_outs, axis=0) \n",
        "\n",
        "_, test_labels, test_enc_outs = test(X_test, y_test, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWjiuyN7swAn",
        "outputId": "e15601d2-d1f7-49c7-de9a-ac4aab4e350c"
      },
      "source": [
        "print(train_labels.shape)\n",
        "print(train_enc_outs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(697008,)\n",
            "(697008, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co-28tCMsv98"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn-y3H0fsy1a",
        "cellView": "form"
      },
      "source": [
        "#@title Predict Function\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "import math\n",
        "\n",
        "def predict(X_tfinal, labels, sklearn_obj):\n",
        "  clf = sklearn_obj\n",
        "  predictions = clf.predict(X_tfinal)\n",
        "\n",
        "  print(\"Accuracy = {:.3f}\".format(accuracy_score(labels, predictions)))\n",
        "  print(f1_score(labels, predictions, average=None))\n",
        "  print(confusion_matrix(labels, predictions))\n",
        "  return predictions, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dzMOZTks9tc",
        "outputId": "90404346-2d21-4b1b-9d72-e8b1ee5ae977"
      },
      "source": [
        "# svm_clf = SVC()\n",
        "# svm_clf.fit(train_enc_outs, train_labels)\n",
        "\n",
        "# print(\"Classifier: SVM\")\n",
        "# svm_preds, svm_labels = predict(test_enc_outs, test_labels, svm_clf)\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=50, n_jobs=-1)\n",
        "rf_clf.fit(train_enc_outs, train_labels)\n",
        "\n",
        "print(\"\\nClassifier: Random Forest\")\n",
        "rf_preds, rf_labels = predict(test_enc_outs, test_labels, rf_clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Classifier: Random Forest\n",
            "Accuracy = 0.968\n",
            "[0.99022483 0.8773958  0.97902913 0.993143   0.93439817 0.91604842\n",
            " 0.79133302 1.         0.83194676 0.8172043  0.90631882 0.78461901\n",
            " 0.99956811 0.99834983 0.98277842 0.83534137 0.87657058 1.\n",
            " 0.93293672 0.89646846 0.97959184 0.98739496 0.39534884 0.99938537\n",
            " 0.93877551 1.         0.58181818 0.87587822 0.71111111 0.99459459\n",
            " 0.98969072 0.         0.         0.         1.         0.        ]\n",
            "[[109556      0      0 ...      0      0      0]\n",
            " [   420   5768      3 ...      0      0      0]\n",
            " [     1      0   5042 ...      0      0      0]\n",
            " ...\n",
            " [     1      0      0 ...      0      0      0]\n",
            " [     0      0      0 ...      0      4      0]\n",
            " [     1      0      0 ...      0      0      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgBuQjrRtGk7"
      },
      "source": [
        "def metric_values(preds, labels):\n",
        "    new_labels = []\n",
        "    new_preds = []\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i] != 0 and labels[i] != tag_to_idx[\"PUN\"]:\n",
        "            new_labels.append(labels[i])\n",
        "            new_preds.append(preds[i])\n",
        "\n",
        "    acc = accuracy_score(new_labels, new_preds)*100\n",
        "    cm = confusion_matrix(new_labels, new_preds)\n",
        "    f = f1_score(new_labels, new_preds, average=None)\n",
        "\n",
        "    print(acc)\n",
        "    print(cm)\n",
        "    print(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m4bATUNwRQh"
      },
      "source": [
        "print(\"Metrics for SVM Classifier:\")\n",
        "metric_values(svm_preds, svm_labels)\n",
        "\n",
        "print(\"\\nMetrics for Random Forest Classifier:\")\n",
        "metric_values(rf_preds, rf_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5B-uy4CwV7Y"
      },
      "source": [
        "preds = svm_clf.predict(enc_out)\n",
        "tags = [idx_to_tag[int(x)] for x in preds]\n",
        "for i in range(len(tags)):\n",
        "    print(f\"{s[0].split()[i]}\\t:\\t{tags[i]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9zVg_jLmhX2"
      },
      "source": [
        "preds = rf_clf.predict(enc_out)\n",
        "tags = [idx_to_tag[int(x)] for x in preds]\n",
        "for i in range(len(tags)):\n",
        "    print(f\"{s[0].split()[i]}\\t:\\t{tags[i]}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}